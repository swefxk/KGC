#!/bin/bash

# 1. è®¾ç½®å·¥ä½œç›®å½•
DATA_DIR="data/wn18rr_custom"
mkdir -p $DATA_DIR
echo "ðŸš€ å¼€å§‹æž„å»º WN18RR æ•°æ®é›† (å›½å†…åŠ é€Ÿç‰ˆ)..."

# 2. å®šä¹‰ä¸‹è½½å‡½æ•° (ä½¿ç”¨åŠ é€Ÿé•œåƒ)
python3 -c "
import os
import urllib.request
import time

# --- æ ¸å¿ƒä¿®æ”¹ï¼šä½¿ç”¨ GitHub Proxy åŠ é€Ÿä¸‹è½½ ---
# åŽŸé“¾æŽ¥: https://raw.githubusercontent.com/...
# åŠ é€Ÿé“¾æŽ¥: https://mirror.ghproxy.com/https://raw.githubusercontent.com/...
base_url = 'https://mirror.ghproxy.com/https://raw.githubusercontent.com/intfloat/SimKGC/main/data/WN18RR/'

files = ['train.txt', 'valid.txt', 'test.txt', 'entity2text.txt', 'relation2text.txt']
target_dir = '$DATA_DIR'

for file in files:
    url = base_url + file
    save_path = os.path.join(target_dir, file)
    print(f'â¬‡ï¸  Downloading {file}...')
    
    # ç®€å•çš„é‡è¯•æœºåˆ¶
    for attempt in range(3):
        try:
            urllib.request.urlretrieve(url, save_path)
            # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼Œç¡®ä¿ä¸æ˜¯ç©ºæ–‡ä»¶
            if os.path.getsize(save_path) > 1000:
                print(f'   âœ… Success: {file}')
                break
            else:
                print('   âš ï¸ Downloaded file too small, retrying...')
        except Exception as e:
            print(f'   âŒ Attempt {attempt+1} failed: {e}')
            time.sleep(2)
    else:
        print(f'ðŸ”¥ Failed to download {file} after 3 attempts.')
        exit(1)
"

# æ£€æŸ¥ä¸Šä¸€æ­¥æ˜¯å¦æˆåŠŸ
if [ $? -ne 0 ]; then
    echo "âŒ ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ç¨åŽé‡è¯•ã€‚"
    exit 1
fi

# 3. æ ¸å¿ƒå¤„ç†è„šæœ¬
echo "âš™ï¸  æ­£åœ¨å¤„ç†æ•°æ®æ ¼å¼..."

python3 -c "
import os

data_dir = '$DATA_DIR'

print('   -> Generating entities.dict and relations.dict...')
entities = set()
relations = set()

try:
    for split in ['train.txt', 'valid.txt', 'test.txt']:
        path = os.path.join(data_dir, split)
        with open(path, 'r', encoding='utf-8') as f:
            for line_idx, line in enumerate(f):
                parts = line.strip().split('\t')
                if len(parts) != 3:
                    print(f'âš ï¸ Skipping malformed line {line_idx} in {split}')
                    continue
                h, r, t = parts
                entities.add(h)
                entities.add(t)
                relations.add(r)
except FileNotFoundError:
    print('âŒ æ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œè¯·ç¡®è®¤ä¸‹è½½æ­¥éª¤æ˜¯å¦æˆåŠŸã€‚')
    exit(1)

sorted_entities = sorted(list(entities))
with open(os.path.join(data_dir, 'entities.dict'), 'w', encoding='utf-8') as f:
    for i, e in enumerate(sorted_entities):
        f.write(f'{i}\t{e}\n')

sorted_relations = sorted(list(relations))
with open(os.path.join(data_dir, 'relations.dict'), 'w', encoding='utf-8') as f:
    for i, r in enumerate(sorted_relations):
        f.write(f'{i}\t{r}\n')

print('   -> Converting text files...')
# è½¬æ¢ entity2text
if os.path.exists(os.path.join(data_dir, 'entity2text.txt')):
    with open(os.path.join(data_dir, 'entity2text.txt'), 'r', encoding='utf-8') as fin, \
         open(os.path.join(data_dir, 'entity2text_custom.txt'), 'w', encoding='utf-8') as fout:
        for line in fin:
            parts = line.strip().split('\t')
            if len(parts) >= 2:
                eid = parts[0]
                text = parts[1]
                name = text.split(': ', 1)[0] if ': ' in text else text
                fout.write(f'{eid}\t{name} [SEP] {text}\n')
    os.replace(os.path.join(data_dir, 'entity2text_custom.txt'), os.path.join(data_dir, 'entity2text.txt'))

# è½¬æ¢ relation2text
if os.path.exists(os.path.join(data_dir, 'relation2text.txt')):
    with open(os.path.join(data_dir, 'relation2text.txt'), 'r', encoding='utf-8') as fin, \
         open(os.path.join(data_dir, 'relation2text_custom.txt'), 'w', encoding='utf-8') as fout:
        for line in fin:
            parts = line.strip().split('\t')
            if len(parts) >= 2:
                fout.write(f'{parts[0]}\t{parts[0]} [SEP] {parts[1]}\n')
    os.replace(os.path.join(data_dir, 'relation2text_custom.txt'), os.path.join(data_dir, 'relation2text.txt'))

print('âœ… Data processing complete!')
"